 # ğŸš€ LLM-Powered Sentiment Intelligence Platform

An **end-to-end NLP and LLM-style sentiment analysis system** built with **Transformer architectures** (BERT, DistilBERT, RoBERTa, XLNet).  
This project combines **modern language models**, **interactive analytics**, and **explainable AI (XAI)** into a **production-ready Streamlit application**.

Designed for **research, applied ML, and industry-facing demos**.

---

## ğŸ”‘ Highlights 
- ğŸ§  **LLM-style Transformers** for sentiment understanding
- ğŸ“Š **Interactive analytics dashboard**
- ğŸ” **Explainable AI (XAI)** for model transparency
- âš¡ **Real-time inference & test streaming**
- ğŸ“ˆ **Model benchmarking & comparison**
- ğŸ§ª **Research-grade evaluation metrics**
- ğŸ§© Modular, extensible, and production-oriented codebase

---

# ğŸ“¸ Application Screenshots

<p align="center">
  <img src="1.jpg" width="900">
</p>

<p align="center">
  <img src="2.jpg" width="900">
</p>

<p align="center">
  <img src="3.jpg" width="900">
</p>


## ğŸ¤– LLM & Transformer Stack

This platform supports multiple **state-of-the-art Transformer models**:

- **BERT** â€“ contextual language understanding
- **DistilBERT** â€“ lightweight LLM-style inference
- **RoBERTa** â€“ robust optimized transformer
- **XLNet** â€“ autoregressive language modeling

All models are fine-tuned for **binary sentiment classification (positive / negative)** using **Hugging Face Transformers**.

---

## ğŸ—‚ï¸ System Architecture
Text Data (CSV)
â†“
Text Cleaning & Tokenization
â†“
Transformer Models (LLMs)
â†“
Predictions & Probabilities
â†“
Explainable AI (XAI)
â†“
Streamlit Analytics Dashboard


---

## ğŸ“ Repository Structure



.
â”œâ”€â”€ Sentiment.py # Streamlit LLM dashboard (EDA, inference, XAI)
â”œâ”€â”€ train_Xformers.py # Batch inference & evaluation pipeline
â”œâ”€â”€ dataset/
â”‚ â”œâ”€â”€ train.csv
â”‚ â””â”€â”€ test.csv
â”œâ”€â”€ *-finetuned/ # Fine-tuned Transformer models
â”œâ”€â”€ *_predictions.csv # Model prediction outputs
â””â”€â”€ README.md


---

## ğŸ“Š Capabilities

### ğŸ” Exploratory Data Analysis (EDA)
- Dataset inspection
- Sentiment distribution
- Missing value analysis

### ğŸ§ª Model Evaluation
- Accuracy, Precision, Recall, F1-score
- Confusion matrices
- Test-set benchmarking

### ğŸ§  Explainable AI (XAI)
- Gradient Ã— Embedding explanations
- Approximate LRP-style relevance
- Attention-based token importance
- Sentence-level relevance scoring
- Visual heatmaps and token highlighting

### â© Real-Time Test Streaming
- Step-by-step inference on test samples
- Live probability tracking
- Model behavior inspection

---

## ğŸ“ Dataset Format

CSV files must contain:

- **Review** â€“ input text
- **Sentiment** â€“ ground truth (`positive` / `negative`)

```csv
Review,Sentiment
"Great experience and service",positive
"Terrible quality and support",negative

ğŸ› ï¸ Installation
pip install streamlit torch transformers pandas numpy matplotlib seaborn scikit-learn


âœ” Compatible with Python 3.8+

â–¶ï¸ Run the LLM Dashboard
streamlit run Sentiment.py


This launches a full-stack LLM analytics interface in your browser.

ğŸ§ª Batch Inference & Evaluation
python train_Xformers.py


Generates model-specific prediction files for benchmarking and comparison.

ğŸ“ˆ Model Benchmarking

The platform compares models across:

Accuracy

Precision / Recall / F1

Class-wise performance

Exportable evaluation metrics

Designed for model selection and research benchmarking.

ğŸ¯ Ideal For

AI / ML Engineer portfolios

NLP & LLM research projects

Explainable AI (XAI) demonstrations

Sentiment intelligence systems

Recruiter-facing technical showcases
